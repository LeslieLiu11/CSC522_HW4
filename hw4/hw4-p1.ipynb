{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6b7939737fd8550c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Clustering Algorithms (20 points) [TA: Vodelina Samatova]\n",
    "\n",
    "In this exercise, you'll be working on different clustering algorithms: KMeans and Hierarchical Clustering Algorithms.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5baa4cb199de4c4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(23)\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_folder = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-db9fd0cf3a566afa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# First, let us load datasets to use for KMeans and Hierarchical Clustering\n",
    "d1 = np.load(f'{data_folder}/hw4-p1-d1.npz')\n",
    "dataset_1 = d1['data']\n",
    "print(f'Dataset 1 is of dimension {dataset_1.shape}')\n",
    "initial_centers = d1['initial']\n",
    "\n",
    "d2 = np.load(f'{data_folder}/hw4-p1-d2.npz')\n",
    "dataset_2 = d2['data']\n",
    "print(f'Dataset 2 is of dimension {dataset_2.shape}')\n",
    "initial_centers = d2['initial']\n",
    "\n",
    "d3 = np.load(f'{data_folder}/hw4-p2-d2.npz')\n",
    "dataset_3 = d3['data']\n",
    "print(f'Dataset 3 is of dimension {dataset_2.shape}')\n",
    "\n",
    "# plot the data \n",
    "plt.scatter(x = dataset_1[:, 0], y=dataset_1[:, 1])\n",
    "plt.title('Dataset 1')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(x = dataset_2[:, 0], y=dataset_2[:, 1])\n",
    "plt.title('Dataset 2')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(x = dataset_3[:, 0], y=dataset_3[:, 1])\n",
    "plt.title('Dataset 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-462c68d3283c3ea2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem 1.1: Cluster SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "alda_calculate_sse",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def alda_calculate_sse(data, cluster_assignments):\n",
    "    \"\"\"\n",
    "    TODO: Write code to calculate the SSE for the dataset 'data' given cluster assignments. Code should be written from\n",
    "    scratch, not use an existing sklearn library to do so (numpy is allowed to use).\n",
    "    \n",
    "    INPUT:\n",
    "          data: the dataset of size (n_samples, n_attributes) where n_samples is the number of samples\n",
    "                and n_attributes is the number of attributes for each data point.\n",
    "          cluster_assignments: a numpy integer vector containing the cluster assignments for each point in data.\n",
    "                           It is of shape (n_attributes, ).\n",
    "          \n",
    "    OUTPUT:\n",
    "          A floating point value containing the SSE\n",
    "    \n",
    "    Allowed functions: numpy mathematical functions\n",
    "    \"\"\"\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-34341874c3493077",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "# assume we're creating a dataset with two clusters \n",
    "practice_data = np.array([[0, 0], [1, 1], [2, 2], [3, 3] ,[4, 4]])\n",
    "# here, 0 means that all points belong to cluster 0\n",
    "# 1 means all points belong to cluster 1\n",
    "practice_cluster_assignments = np.array([0, 0, 1, 1, 1]) \n",
    "\n",
    "# Let's calculate its SSE\n",
    "print(f'For given data, SSE = {alda_calculate_sse(practice_data, practice_cluster_assignments)}')\n",
    "# should be 5\n",
    "\n",
    "plt.scatter(x = practice_data[:, 0], y=practice_data[:, 1], c=practice_cluster_assignments)\n",
    "plt.title('Dataset 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "alda_calculate_sse-public",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let us evaluate the function on the practice dataset \n",
    "practice_ds = np.load(f'{data_folder}/hw4-p1-practice.npz')\n",
    "practice_data = practice_ds['data']\n",
    "practice_initial_centers = practice_ds['initial']\n",
    "practice_sse = alda_calculate_sse(practice_data, practice_initial_centers)\n",
    "np.testing.assert_almost_equal(practice_sse, 2554.26922225574)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "alda_calculate_sse-private",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember, we will have hidden tests as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4ee68e41d7bd2291",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem 1.2: K-Means Clustering\n",
    "\n",
    "In this problem, you will be using the [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) sklearn **library**,  to perform k-means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "alda_kmeans",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def alda_kmeans(data, k, initial_centers, max_iter):\n",
    "    \"\"\"\n",
    "    TODO: Write code to perform k-means clustering on the data matrix given by the 'data' variable using the kmeans. \n",
    "    \n",
    "    INPUT:\n",
    "        data: A 2D numpy array of shape (n_samples, n_attributes) where n_samples is the number of samples\n",
    "              and n_attributes is the number of attributes for each data point.\n",
    "        k: An integer, gives the number of clusters to calculate in kmeans\n",
    "        initial_centers: A numpy array of shape (k, n_attributes) containing the initial centers\n",
    "        max_iter: max. number of iterations to run for k-means\n",
    "    \n",
    "    OUTPUT:\n",
    "        A numpy ndarray of shape (n_samples, ) providing the cluster assignments\n",
    "        Cluster assignment values range between 0 and k-1.\n",
    "    \n",
    "    NOTE 1: Scikit-learn KMeans Reference: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "    NOTE 2: For reproducibility, use the initial_centers variable for the init agrument in KMeans, \n",
    "            specifying initial centers; you'll also have to set n_init = 1 to remove any warnings.\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ca11f4482564869d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "# let us initialize some variables first\n",
    "practice_k = 2 # to represent number of clusters\n",
    "\n",
    "practice_ds = np.load(f'{data_folder}/hw4-p1-practice.npz')\n",
    "# the dataset is stored here\n",
    "practice_data = practice_ds['data']\n",
    "# initial cluster assignments are stored in this variable\n",
    "# We use these to ensure a deterministic answer (for testing purposes)\n",
    "practice_initial_assignments = practice_ds['initial']\n",
    "# calculate initial centers\n",
    "practice_centers = []\n",
    "for practice_c in np.unique(practice_initial_assignments):\n",
    "    p_current_cluster_data = practice_data[practice_initial_assignments == practice_c, : ]\n",
    "    p_current_cluster_centers = np.mean(p_current_cluster_data, axis=0)\n",
    "    practice_centers.append(p_current_cluster_centers)\n",
    "\n",
    "# convert practice_centers to a numpy array \n",
    "practice_centers = np.array(practice_centers)\n",
    "\n",
    "# call kmeans\n",
    "practice_assignments = alda_kmeans(data=practice_data, k=practice_k,\\\n",
    "                                       initial_centers=practice_centers, max_iter=2)\n",
    "\n",
    "print(f'SSE of KMeans on practice dataset is \\\n",
    "{alda_calculate_sse(practice_data, practice_assignments)}') # Should be ~ 133.045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "alda_kmeans-public",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Public Test Cases\n",
    "# let us initialize some variables first\n",
    "test_k = 3 # to represent number of clusters\n",
    "\n",
    "test_ds = np.load(f'{data_folder}/hw4-p1-d1.npz')\n",
    "# the dataset is stored here\n",
    "test_data = test_ds['data']\n",
    "# initial cluster assignments are stored in this variable\n",
    "test_initial_assignments = test_ds['initial']\n",
    "\n",
    "# calculate initial centers\n",
    "test_centers = []\n",
    "for test_c in np.unique(test_initial_assignments):\n",
    "    test_cluster_data = test_data[test_initial_assignments == test_c, : ]\n",
    "    test_cluster_centers = np.mean(test_cluster_data, axis=0)\n",
    "    test_centers.append(test_cluster_centers)\n",
    "\n",
    "# convert practice_centers to a numpy array \n",
    "test_centers = np.array(test_centers)\n",
    "\n",
    "# call kmeans\n",
    "test_assignments = alda_kmeans(data=test_data, k=test_k,\\\n",
    "                                       initial_centers=test_centers, max_iter=4)\n",
    "\n",
    "\n",
    "np.testing.assert_almost_equal(alda_calculate_sse(test_data, test_assignments), 529.2865169916909)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "alda_kmeans-prviate",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remember, we will have hidden test cases too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we have some code to visualize your k-means clustering on the three toy datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ae55b707db4c799f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def kmeans(k,ds, title='Plot'):\n",
    "    # the dataset is stored here\n",
    "    data = ds['data']\n",
    "    # initial cluster assignments are stored in this variable\n",
    "    initial_assignments = ds['initial']\n",
    "\n",
    "    # calculate initial centers\n",
    "    centers = []\n",
    "    for c in np.unique(initial_assignments):\n",
    "        cluster_data = data[initial_assignments == c, : ]\n",
    "        cluster_centers = np.mean(cluster_data, axis=0)\n",
    "        centers.append(cluster_centers)\n",
    "\n",
    "    # convert practice_centers to a numpy array \n",
    "    centers = np.array(centers)\n",
    "    assignment = alda_kmeans(data=data, k=k, initial_centers=centers, max_iter=300)\n",
    "\n",
    "    plt.scatter(x = data[:, 0], y=data[:, 1], c=assignment)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d670fab4b0c78bd5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ds1 = np.load(f'{data_folder}/hw4-p1-d1.npz')\n",
    "assignment1 = kmeans(3,ds1, 'Blobs')\n",
    "ds2 = np.load(f'{data_folder}/hw4-p1-d2.npz')\n",
    "assignment2 = kmeans(2,ds2, 'Two moons')\n",
    "ds3 = np.load(f'{data_folder}/hw4-p2-d2.npz')\n",
    "assignment3 = kmeans(2,ds3, 'Two moons (loose)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f12fb81ed379eec8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.2.1: k-means++ (Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99e6850adcf42eec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[k-means++](https://en.wikipedia.org/wiki/K-means%2B%2B) is a clustering algorithm with the optimized centroids initialization, fortunately, the built-in [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) function in sklearn applied k++ centroid initialization as a default, we will compare how many iterations are required to get convergence with and without using k++ algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bf2a0e07e663a5cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def kmeans_kplusplus(k,ds):\n",
    "    # the dataset is stored here\n",
    "    data = ds['data']\n",
    "    kmeans = KMeans(n_clusters=k, n_init=1, max_iter=300, verbose=1)\n",
    "    return kmeans.fit(data).labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-326c5ca2618a9163",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('*'*20 + \"  See how many iterations are required without k++ initialization  \" + '*'*20)\n",
    "assignment_without_kplusplus = kmeans(3,ds1)\n",
    "print('*'*20 + \"  See how many iterations are required with k++ initialization  \" + '*'*20)\n",
    "assignment_with_kplusplus = kmeans_kplusplus(3,ds1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a17b634c7178d99b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1.3. Agglomerative/Hierarchical Clustering\n",
    "\n",
    "You need to implement the same function, agglomerative clusting using the [AgglomerativeClustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html) library from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "alda_agglomerative",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def alda_agglomerative(data, k, linkage):\n",
    "    \"\"\"\n",
    "    TODO: Perform agglomerative clustering on the data from the 'data' variable. Type of linkage is \n",
    "    specified by 'linkage'\n",
    "    INPUT:\n",
    "         data: A 2D numpy array of shape (n_samples, n_attributes) where n_samples is the number of samples\n",
    "              and n_attributes is the number of attributes for each data point.\n",
    "         k: An integer, gives the number of clusters to calculate \n",
    "         linkage: A string, can be one of the three: 'single', 'complete', 'average'\n",
    "         \n",
    "    OUTPUT:\n",
    "         A numpy ndarray of shape (n_samples, ) providing the cluster assignments. \n",
    "         Cluster assignment values range between 0 and k-1.\n",
    "    \n",
    "         \n",
    "    \"\"\"     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "# let us initialize some variables first\n",
    "practice_k = 2 # to represent number of clusters\n",
    "\n",
    "practice_ds = np.load(f'{data_folder}/hw4-p1-d2.npz')\n",
    "# the dataset is stored here\n",
    "practice_data = practice_ds['data']\n",
    "\n",
    "# perform hierarchical clustering using complete linkage\n",
    "linkage_type = 'complete'\n",
    "practice_cluster_assignments = alda_agglomerative(practice_data, practice_k, linkage_type)\n",
    "\n",
    "print(f'SSE of agglomerative clustering with {linkage_type} linkage \\\n",
    "is {alda_calculate_sse(practice_data, practice_cluster_assignments)}') # Should be ~ 81.539\n",
    "\n",
    "# plot the cluster assignments\n",
    "plt.scatter(practice_data[:, 0], practice_data[:, 1], c=practice_cluster_assignments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "alda_agglomerative-public",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Public Tests\n",
    "test_k = 2 # to represent number of clusters\n",
    "\n",
    "test_ds = np.load(f'{data_folder}/hw4-p1-d2.npz')\n",
    "# the dataset is stored here\n",
    "test_data = test_ds['data']\n",
    "\n",
    "# perform hierarchical clustering using single linkage\n",
    "linkage_type = 'single'\n",
    "test_cluster_assignments = alda_agglomerative(test_data, test_k, linkage_type)\n",
    "\n",
    "np.testing.assert_almost_equal(alda_calculate_sse(test_data, test_cluster_assignments), 121.76952070250866)\n",
    "\n",
    "# plot the clusters\n",
    "plt.scatter(test_data[:, 0], test_data[:, 1], c=test_cluster_assignments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "alda_agglomerative-private",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember, we'll have hidden test cases too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-682a59024ed2e28d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3.1: Dendrogram\n",
    "\n",
    "SKlearn doesn't have a built-in method for dendograms, so we'll be using [scipy's dendrogram tool](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html)\n",
    "\n",
    "Let's try the dendrogram on the `dataset_2` we had above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as hierarchy\n",
    "\n",
    "# Note the method='single'\n",
    "single_link = hierarchy.linkage(dataset_2, method='single')\n",
    "hierarchy.dendrogram(single_link)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-acc7da7daa16c671",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, using the same logic as the above code, implement the complete-link dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "complete_link",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that it is REQUIRED to use complete_link_clustering and dendrogram \n",
    "# variables names when creating your clustering and dendrogram\n",
    "\n",
    "#TODO: implement the complete-link dendrogram\n",
    "\n",
    "complete_link_clustering = None\n",
    "dendrogram = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "complete_link-public",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(dendrogram['icoord'][5][2],34.375)\n",
    "np.testing.assert_almost_equal(complete_link_clustering[24][2],0.017184987030773195)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1ddf08024454c37f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Interpreting the dendrograms\n",
    "\n",
    "By looking at the dendrograms, what **difference** do you see between single-link clustering and complete-link? Which one has performed better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c5e94274d584716b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1.4. DBSCAN\n",
    "Now we'll look at a dataset where neither K-means nor Agglomerative Clustering does well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6694652cde4df610",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Example 4.1: Limitations of k-means and hierarchical clustering\n",
    "First, let's take another look at the scatter plot of `dataset_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = dataset_3[:, 0], y=dataset_3[:, 1])\n",
    "plt.title('Dataset 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1e75f176b884617b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Trying K-means\n",
    "Let's try a K-means on this dataset with `n_clusters=2` and the rest of the same paramaters used previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try K-means\n",
    "kmeans = KMeans(n_clusters=2, init='random', n_init=1, max_iter=10, verbose=1)\n",
    "results = kmeans.fit(dataset_3)\n",
    "plt.scatter(x = dataset_3[:, 0], y=dataset_3[:, 1], c=results.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce16a6b3a18c09be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Trying Agglomerative\n",
    "Now let's try a agglomerative clustering on this dataset with `n_clusters=2`. Try it with both `complete` and `single` linkage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try agglomerative clustering\n",
    "agglom = AgglomerativeClustering(n_clusters=2, linkage=\"single\")\n",
    "results = agglom.fit(dataset_3)\n",
    "plt.scatter(x = dataset_3[:, 0], y=dataset_3[:, 1], c=results.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try agglomerative clustering\n",
    "agglom = AgglomerativeClustering(n_clusters=2, linkage=\"complete\")\n",
    "results = agglom.fit(dataset_3)\n",
    "plt.scatter(x = dataset_3[:, 0], y=dataset_3[:, 1], c=results.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b1cf827f8dbc499b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now is the time to try DBScan on `dataset_3`. Will it make better clusters? We don't know! Let's see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dddf9abdbbd27ca0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Problem 1.4.1: DBSCAN\n",
    "\n",
    "Finding the right number for `eps` and `min_samples` (min points) can be a bit touchy. **A good rule of thumb is to choose `min_samples` to be TWICE the dimension of the feature space.**\n",
    "\n",
    "As the first step, complete the function `plot_dbscan`. The goal is to have a function which gets `epsilon` and `min_samples` and performs DBScan clustering on `dataset_3`. Using [the sklearn documentation for DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html) can be so helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "dbscan",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "#TODO: complete the following function\n",
    "def plot_dbscan(epsilon, min_samples):\n",
    "    # Output:\n",
    "    #   clustering: a fitted instance of DBScan clustering\n",
    "    #   plt.scatter: scatter plot of DBScan\n",
    "    x = dataset_3[:, 0]\n",
    "    y = dataset_3[:, 1]\n",
    "    clustering = None\n",
    "\n",
    "    return clustering, plt.scatter(x=x, y=y, c=clustering.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "dbscan-public",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(plot_dbscan(0.1, 4)[0].labels_[5],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-653f8b8427f36ce4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's play around with different epsilons and see how it affects the result of DBScan clustering. What version of eps worked best for you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Since we're in two-dimensional space, we will set min points as 2*2=4\n",
    "min_pts = 4\n",
    "\n",
    "#Try with different eps from 0.05 to 0.25\n",
    "plot_dbscan(0.5, min_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What value of eps worked best? How does eps affect your clustering? ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4d060bd98994c2f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Problem 1.4.2: Finding a Reasonable Value for Epsilon in DBSCAN\n",
    "In the real world, we cannot find a good epsilon based on guessing. So we'll be using the method discussed in class to determine a good `eps` for a given `min_samples`. That is, if `min_samples=k`, plot the distance from each point to its kth nearest neighbor. Then, sort those distances and plot them. Finally, locate on the graph where the sharpest change begins, and use that distance as your `eps`. You might have to play with values near that to get a good clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "#Get the nearest neighbors\n",
    "# the reason why we set min_pts as 4 is discussed above\n",
    "min_pts = 4\n",
    "neighbors = NearestNeighbors(n_neighbors=min_pts).fit(dataset_3)\n",
    "distances, indices = neighbors.kneighbors(dataset_3)\n",
    "#Sort them\n",
    "dis_to_nth_nn = sorted(distances[:,min_pts-1])\n",
    "#Plot\n",
    "plt.plot(dis_to_nth_nn)\n",
    "plt.title(f'(Identifying best Eps value for MinPts={min_pts}')\n",
    "plt.xlabel(\"nth Greatest Datapoint\")\n",
    "plt.ylabel(f'Distance to {min_pts}th Nearest Neighbor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4babf06765842254",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As we can see, the sharpest cange begins at around the 175th greatest datapoint, which corresponds to a value of around `0.15`. So that can serve as a starting point for trying out different `eps` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try different eps from 0.15-0.22. 0.21 seems to be the best\n",
    "\n",
    "# plot_dbscan(0.15, min_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-401b3de64d80c619",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see, for some datasets, the output of DBScan can be way more acceptable than k-means and hierarchical clustering. We just have to find good values of epsilon and min_samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
